{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d6f65f3-17c1-41c6-8a8d-63af5bf111e0",
   "metadata": {},
   "source": [
    "## Now that we know a little Python: using AI as a helper\n",
    "\n",
    "Let's see if we can use [ChatGPT](https://chat.openai.com/) to walk us through how to do a complicated problem.\n",
    "\n",
    "In April 2024, the Washington Post published [Inside the secret list of websites that make AI like ChatGPT sound smart\n",
    "](https://www.washingtonpost.com/technology/interactive/2023/ai-chatbot-learning/). This story analyzed the [C4 dataset](https://huggingface.co/datasets/allenai/c4), a selection of data that's part of the training process for large language models like ChatGPT.\n",
    "\n",
    "It showed how much content was from Wikipedia, whether business or hobby websites were more popular, and even included a tool that allowed you to search whether your website was included in the dataset.\n",
    "\n",
    "Let's see if we can do our own analysis! We're going to use the C4M dataset, which is the multilingual version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107ecf2d-a154-4ab9-8feb-df184f82c0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 400\n",
    "\n",
    "# We're using a CSV right from the internet, but you can visit the URL if you'd like\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/jsoma/2024-birn/main/01-pandas/c4m-tiny-sample.csv\", nrows=3000)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c4a1bf-ddec-44e8-916b-74a17918d6a5",
   "metadata": {},
   "source": [
    "## Let's get crazy\n",
    "\n",
    "What langage is each one of these in? Let's get crazy by [seeing what ChatGPT can help us do](https://chatgpt.com/). This will be an exercise in asking specific questions, troubleshooting problems, and having a back-and-forth conversation with AI tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bbed77-081d-49de-a6ab-7d7e35529543",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8115a3e-6def-4e34-a48f-fa826266e4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from langdetect import detect\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# Assuming df is your DataFrame and 'text' is the column containing the text data\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except LangDetectException:\n",
    "        return 'unknown'  # In case language detection fails\n",
    "\n",
    "# Add the 'lang' column to the DataFrame\n",
    "df['lang'] = df['text'].progress_apply(detect_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69ad60d-c584-477a-94d2-d568c742ed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9ea924-9537-446e-be69-1a16e9decc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect_langs\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "\n",
    "def detect_language_with_confidence(text):\n",
    "    try:\n",
    "        detections = detect_langs(text)\n",
    "        if detections:\n",
    "            top_detection = detections[0]\n",
    "            return top_detection.lang, top_detection.prob\n",
    "        else:\n",
    "            return 'unknown', 0.0\n",
    "    except LangDetectException:\n",
    "        return 'unknown', 0.0  # In case language detection fails\n",
    "\n",
    "# Apply the function to get both language and confidence score\n",
    "df[['lang', 'confidence']] = df['text'].progress_apply(lambda x: pd.Series(detect_language_with_confidence(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13894383-ff8e-4441-b58f-9b84fa7173ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2023a4-8c88-425d-8af8-000efd85051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lang'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7d3d29-83cc-46e1-be19-d7bd3e878529",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502ca4f3-b956-417b-aa5b-b1adf1faa1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "# URL for the lid.176.bin model\n",
    "url = \"https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin\"\n",
    "output_path = \"lid.176.bin\"\n",
    "\n",
    "# Download the file\n",
    "print(\"Downloading lid.176.bin...\")\n",
    "urllib.request.urlretrieve(url, output_path)\n",
    "print(\"Download complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e89cac8-644c-4573-9e87-eb47c961bef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "# Load the pre-trained language identification model\n",
    "model = fasttext.load_model('lid.176.bin')\n",
    "\n",
    "def detect_language_fasttext(text):\n",
    "    # Clean the text by removing newlines\n",
    "    cleaned_text = text.replace('\\n', ' ').strip()\n",
    "    predictions = model.predict(cleaned_text)\n",
    "    lang = predictions[0][0].replace('__label__', '')\n",
    "    confidence = predictions[1][0]\n",
    "    return lang, confidence\n",
    "\n",
    "df[['lang', 'confidence']] = df['text'].progress_apply(lambda x: pd.Series(detect_language_fasttext(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50327775-16a4-4bc5-8bdb-5f0b6b4366a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lang'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7f423e-f872-41fd-8bba-da9cda69a6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['lang'].isin(['hr', 'sr'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e883a270-1308-45a4-a3b3-98ba387bd8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db9f4e4-d581-4e9d-b6d7-b0f416fb2d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['lang'].isin(['hr', 'sr'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38403878-9be7-4e24-baa4-a0d8d25d8286",
   "metadata": {},
   "source": [
    "## Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9afecf-2db8-4dcd-8663-4c90669ef69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"edited.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
